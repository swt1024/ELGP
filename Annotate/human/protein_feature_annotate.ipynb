{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate features for proteins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 Annotate pLI and pLoF score for valid proteins. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1.1 Extract all protein molecules from a filtered LPPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example usage\n",
    "inter_file = 'inter_with_valid_lnc.csv'\n",
    "inter = pd.read_csv(inter_file)\n",
    "\n",
    "# Concatenate two columns into a new Series and remove duplicates\n",
    "molecule = pd.concat([inter['Node_i'], inter['Node_j']]).reset_index(drop=True)\n",
    "molecule_df = pd.DataFrame(molecule, columns=['molecule'])\n",
    "molecule_df = molecule_df.drop_duplicates()\n",
    "\n",
    "protein_file = '../../data/LPPI/human/ensembl/protein.csv'\n",
    "proteins = pd.read_csv(protein_file)\n",
    "\n",
    "proteins = proteins[proteins['protein_ID'].isin(molecule_df['molecule'])]\n",
    "\n",
    "# Export to CSV file\n",
    "protein_file = 'proteins.csv'\n",
    "proteins.to_csv(protein_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1.2 Annotate pLI score for valid proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "valid_protein = pd.read_csv(\"proteins.csv\", dtype=str)\n",
    "pLoF = pd.read_csv(\"../../protein/human/pLoF.txt\", sep='\\t')\n",
    "\n",
    "# Filtering required columns from pLoF\n",
    "pLoF = pLoF[['gene','oe_lof_upper', 'obs_lof', 'exp_lof', 'oe_lof', 'lof_z', 'pLI']]\n",
    "\n",
    "# Merging on 'protein' column from valid_protein and 'gene' column from pLoF\n",
    "protein_pLI = pd.merge(valid_protein, pLoF, left_on='protein', right_on='gene', how='inner')\n",
    "protein_pLI = protein_pLI.drop(columns=['gene', 'protein'])\n",
    "\n",
    "# Extract rows containing NaN values in protein_pLI\n",
    "na_score_protein = protein_pLI[protein_pLI.isna().any(axis=1)]\n",
    "na_score_protein = na_score_protein[['protein_ID']]\n",
    "\n",
    "protein_pLI_cleaned = protein_pLI.dropna()\n",
    "\n",
    "pLI_means = protein_pLI_cleaned.groupby('protein_ID').mean().reset_index()\n",
    "\n",
    "# Save results\n",
    "pLI_means.to_csv('protein_annotation.csv', index=False)\n",
    "na_score_protein.to_csv('NA_score_protein.csv', index=False)  # Saving rows with NaN values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1.3 Convert oe_lof&lof_z to p-value and get log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import poisson, norm\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"protein_annotation.csv\")\n",
    "\n",
    "# Calculate p-value for each observation using the Poisson distribution\n",
    "df[\"oe_lof_pval\"] = df.apply(lambda row: poisson.cdf(row['obs_lof'], row['exp_lof']), axis=1)\n",
    "\n",
    "# Calculate p-value for lof_z using a two-tailed Z-test\n",
    "df[\"lof_z_pval\"] = df[\"lof_z\"].apply(lambda x: 2 * (1 - norm.cdf(abs(x))) if pd.notna(x) else np.nan)\n",
    "\n",
    "# Apply a log10 transformation to p-values with a small number adjustment\n",
    "df[\"log_oe_lof_pval\"] = df[\"oe_lof_pval\"].apply(lambda x: np.log10(x + 1e-10))\n",
    "df[\"log_lof_z_pval\"] = df[\"lof_z_pval\"].apply(lambda x: np.log10(x + 1e-10))\n",
    "df[\"log_pLI\"] = df[\"pLI\"].apply(lambda x: np.log10(x) if pd.notna(x) and x > 0 else np.nan)\n",
    "\n",
    "# Select columns to keep\n",
    "df = df[['protein_ID', \"log_oe_lof_pval\", \"log_lof_z_pval\", \"log_pLI\"]]\n",
    "\n",
    "# Save the transformed dataset\n",
    "df.to_csv(\"transformed_protein_annotation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1.4 Delete interaction with protein which have NA pLI score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inter = pd.read_csv(\"inter_with_valid_lnc.csv\")\n",
    "invalid_protein = pd.read_csv(\"NA_score_protein.csv\")\n",
    "\n",
    "inter = inter[~inter['Node_i'].isin(invalid_protein['protein_ID'])]\n",
    "inter = inter[~inter['Node_j'].isin(invalid_protein['protein_ID'])]\n",
    "\n",
    "inter.to_csv(\"valid_inter.csv\", index=False)\n",
    "\n",
    "#cell_lines = ['HeLa','HepG2','K562', 'ac']\n",
    "tissues = ['heart','lung','stomach']\n",
    "for tissue in tissues:\n",
    "\tlnc = pd.read_csv(f\"{tissue}_annotation.csv\")\n",
    "\tlnc = lnc[lnc['lncRNA_ID'].isin(inter['Node_i'])]\n",
    "\n",
    "\tlnc.to_csv(f\"valid_{tissue}_annotation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 Calculate edge wight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted interaction file has been successfully saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the input CSV file\n",
    "inter = pd.read_csv(\"valid_inter.csv\")\n",
    "\n",
    "# Ensure (Node_i, Node_j) and (Node_j, Node_i) are considered the same edge\n",
    "# Sort each pair so that the smaller node always comes first\n",
    "inter[['Node_i', 'Node_j']] = inter[['Node_i', 'Node_j']].apply(lambda x: tuple(sorted(x)), axis=1, result_type='expand')\n",
    "\n",
    "# Compute the weight (number of occurrences of each edge)\n",
    "inter['weight'] = inter.groupby(['Node_i', 'Node_j']).transform('size')\n",
    "\n",
    "# Remove duplicate edges, keeping only one occurrence per (Node_i, Node_j) pair\n",
    "inter = inter.drop_duplicates(subset=['Node_i', 'Node_j'])\n",
    "\n",
    "inter.columns = ['source', 'target', 'weight']\n",
    "\n",
    "# Save the weighted edge list to a new CSV file\n",
    "inter.to_csv('weighted_valid_inter.csv', index=False)\n",
    "\n",
    "print(\"Weighted interaction file has been successfully saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPI统计结果：\n",
      "lncRNA数量：51899\n",
      "protein数量：3165\n",
      "边的数量：480546\n",
      "\n",
      "PPI统计结果：\n",
      "protein数量：17749\n",
      "边的数量：1130619\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "lppi = pd.read_csv(\"valid_inter.csv\")\n",
    "\n",
    "# 根据第一列前缀是否为 'l' 来划分 LPI 和 PPI\n",
    "LPI = lppi[lppi.iloc[:, 0].str.startswith('l')]\n",
    "PPI = lppi[~lppi.iloc[:, 0].str.startswith('l')]\n",
    "\n",
    "# 统计LPI中lncRNA、protein数量和边数量\n",
    "lncRNA_count_LPI = LPI.iloc[:, 0].nunique()\n",
    "protein_count_LPI = LPI.iloc[:, 1].nunique()\n",
    "edges_count_LPI = len(LPI)\n",
    "\n",
    "# 统计PPI中protein数量和边数量（两列均为protein）\n",
    "protein_count_PPI = pd.unique(PPI.iloc[:, [0, 1]].values.ravel()).size\n",
    "edges_count_PPI = len(PPI)\n",
    "\n",
    "# 输出统计结果\n",
    "print(\"LPI统计结果：\")\n",
    "print(f\"lncRNA数量：{lncRNA_count_LPI}\")\n",
    "print(f\"protein数量：{protein_count_LPI}\")\n",
    "print(f\"边的数量：{edges_count_LPI}\")\n",
    "\n",
    "print(\"\\nPPI统计结果：\")\n",
    "print(f\"protein数量：{protein_count_PPI}\")\n",
    "print(f\"边的数量：{edges_count_PPI}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esslnc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
