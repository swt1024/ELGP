{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e57edae",
   "metadata": {},
   "source": [
    "## Obtaining essential lncRNA genes in different tissues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de0ea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection essential genes for heart saved successfully.\n",
      "Intersection essential genes for lung saved successfully.\n",
      "Intersection essential genes for brain saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define tissues and model names\n",
    "human_tissues = ['heart','lung','stomach']\n",
    "mouse_tissues = ['heart','lung','brain']\n",
    "model_names = ['SVM', 'MLP']\n",
    "\n",
    "for tissue in mouse_tissues:\n",
    "    # Load lncRNA data\n",
    "    lnc = pd.read_csv(\"../../data/LPI/mouse/lncRNA.csv\")\n",
    "    lnc = lnc[['lncRNA_ID', 'gene_id', 'symbol','chr','start','end','strand']]\n",
    "    \n",
    "    # List to store essential genes predicted by each model\n",
    "    all_predictions_ess = []\n",
    "\n",
    "    # Iterate over models\n",
    "    for model in model_names:\n",
    "        # Read prediction file for the current model\n",
    "        prediction = pd.read_csv(f\"../../results/mouse/{model}_predictions_{tissue}.csv\", dtype='str')\n",
    "        \n",
    "        # Filter for essential genes (Pre_Label == '1')\n",
    "        prediction_ess = prediction[prediction['Pre_Label'] == '1']\n",
    "        prediction_ess = prediction_ess[['lncRNA_ID']]\n",
    "        \n",
    "        # Merge the predicted essential genes with lncRNA data\n",
    "        prediction_ess = pd.merge(prediction_ess, lnc, on='lncRNA_ID', how=\"inner\")\n",
    "        prediction_ess.to_csv(f\"../../results/mouse/{model}_{tissue}_ess.csv\", index=False)\n",
    "        \n",
    "        # Append the essential genes (as a set) for the current model\n",
    "        all_predictions_ess.append(prediction_ess)  # Use set to store lncRNA_ID for intersection\n",
    "    \n",
    "    # Calculate the intersection (common essential genes across all models)\n",
    "    intersection_ess = all_predictions_ess[0]  # Initialize with the first model's essential genes\n",
    "    for ess_set in all_predictions_ess[1:]:\n",
    "        intersection_ess.merge(ess_set, on='lncRNA_ID', how='inner')\n",
    "    \n",
    "    # Save the result to a CSV file\n",
    "    intersection_ess.to_csv(f\"../../results/mouse/{tissue}_essential_genes.csv\", index=False)\n",
    "\n",
    "    print(f\"Intersection essential genes for {tissue} saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d173c2c9",
   "metadata": {},
   "source": [
    "## Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680a6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define tissues\n",
    "mouse_tissues = ['heart', 'lung', 'brain']\n",
    "human_tissues = ['heart', 'lung', 'stomach']\n",
    "\n",
    "# Initialize an empty DataFrame to store combined results\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Read and concatenate all tissue essential gene files\n",
    "for tissue in mouse_tissues:\n",
    "    df = pd.read_csv(f\"../../results/mouse/{tissue}_essential_genes.csv\")\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Drop duplicate rows based on all columns\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "# Save the union result to CSV\n",
    "combined_df.to_csv(\"../../results/mouse/mouse_essential_genes_union.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbb6d8d",
   "metadata": {},
   "source": [
    "CSV2bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a43adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to convert CSV to valid 6-column BED format\n",
    "def convert_csv_to_bed(csv_file_path, bed_file_path):\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Check required columns\n",
    "    required_columns = ['chr', 'start', 'end', 'lncRNA_ID', 'strand']\n",
    "    if not all(column in df.columns for column in required_columns):\n",
    "        raise ValueError(\"Missing required columns in CSV.\")\n",
    "\n",
    "    # Construct BED columns in correct order\n",
    "    df_bed = pd.DataFrame()\n",
    "    df_bed['chr'] = df['chr']\n",
    "    df_bed['start'] = df['start'].astype(int)\n",
    "    df_bed['end'] = df['end'].astype(int)\n",
    "    df_bed['name'] = df['lncRNA_ID']\n",
    "    df_bed['score'] = 0\n",
    "    df_bed['strand'] = df['strand']\n",
    "\n",
    "    # Save as BED (tab-separated, no header/index)\n",
    "    df_bed.to_csv(bed_file_path, sep='\\t', header=False, index=False)\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = '../../results/mouse/mouse_essential_genes_union.csv'\n",
    "bed_file_path = 'mouse_essential_genes_union.bed'\n",
    "convert_csv_to_bed(csv_file_path, bed_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f2f0a",
   "metadata": {},
   "source": [
    "### Run get_overlap.sh to find duplicate essential lncRNA genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c36efcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merge completed using longest gene per group. Output saved to: deduplicated_mouse_essential_genes.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Input file paths\n",
    "csv_file = '../../results/mouse/mouse_essential_genes_union.csv'\n",
    "overlap_file = 'mouse_overlapping_genes.txt'\n",
    "output_file = 'deduplicated_mouse_essential_genes.csv'\n",
    "\n",
    "# Load the original annotation table\n",
    "df = pd.read_csv(csv_file)\n",
    "df['length'] = df['end'] - df['start']  # Calculate gene length for selecting representatives\n",
    "\n",
    "# Load the overlapping gene pairs (fully overlapping based on BEDTools results)\n",
    "merge_pairs = pd.read_csv(overlap_file, sep='\\s+', header=None, names=['A', 'B'])\n",
    "\n",
    "# === Build union-find structure (disjoint set) to group overlapping genes ===\n",
    "parent = {}\n",
    "\n",
    "def find(x):\n",
    "    parent.setdefault(x, x)\n",
    "    if parent[x] != x:\n",
    "        parent[x] = find(parent[x])\n",
    "    return parent[x]\n",
    "\n",
    "def union(x, y):\n",
    "    parent[find(y)] = find(x)\n",
    "\n",
    "# Apply union for all overlapping pairs\n",
    "for a, b in zip(merge_pairs['A'], merge_pairs['B']):\n",
    "    union(a, b)\n",
    "\n",
    "# Group all genes by their leader node in the union-find structure\n",
    "groups = defaultdict(set)\n",
    "for gene in set(merge_pairs['A']).union(set(merge_pairs['B'])):\n",
    "    groups[find(gene)].add(gene)\n",
    "\n",
    "# === Determine representative gene per group: longest one ===\n",
    "merge_map = {}  # representative lncRNA_ID → list of merged lncRNA_IDs\n",
    "for group in groups.values():\n",
    "    group_df = df[df['lncRNA_ID'].isin(group)]\n",
    "    rep_row = group_df.loc[group_df['length'].idxmax()]  # select longest gene\n",
    "    rep_id = rep_row['lncRNA_ID']\n",
    "    other_ids = set(group) - {rep_id}\n",
    "    merge_map[rep_id] = list(other_ids)\n",
    "\n",
    "# === Build final output ===\n",
    "# Retain entries that were never merged + representative entries\n",
    "merged_ids = set(merge_pairs['B'])  # IDs that were merged into others\n",
    "all_rep_ids = set(merge_map.keys())\n",
    "retained_ids = set(df['lncRNA_ID']) - merged_ids\n",
    "final_ids = retained_ids.union(all_rep_ids)\n",
    "\n",
    "# Filter the dataframe\n",
    "df_merged = df[df['lncRNA_ID'].isin(final_ids)].copy()\n",
    "\n",
    "# Add a column showing which IDs were merged into each representative\n",
    "df_merged['Merged_IDs'] = df_merged['lncRNA_ID'].apply(lambda x: ';'.join(merge_map[x]) if x in merge_map else '')\n",
    "\n",
    "# Drop the temporary length column\n",
    "df_merged.drop(columns='length', inplace=True)\n",
    "\n",
    "# Save the result\n",
    "df_merged.to_csv(output_file, index=False)\n",
    "print(f\"✅ Merge completed using longest gene per group. Output saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010378d1",
   "metadata": {},
   "source": [
    "## Obtaining essential lncRNA genes in different tissues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf79418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load the merged file and reconstruct merge_map ===\n",
    "# The file should contain columns: lncRNA_ID, Merged_IDs\n",
    "merged_df = pd.read_csv(\"deduplicated_mouse_essential_genes.csv\")\n",
    "\n",
    "# Build merge_map: representative → [merged_IDs]\n",
    "merge_map = {}\n",
    "\n",
    "for _, row in merged_df.iterrows():\n",
    "    rep_id = row['lncRNA_ID']\n",
    "    if pd.notna(row.get('Merged_IDs')) and row['Merged_IDs'].strip():\n",
    "        merged_list = row['Merged_IDs'].split(';')\n",
    "        merge_map[rep_id] = merged_list\n",
    "\n",
    "# Create reverse map: lncRNA_ID (any member) → representative\n",
    "reverse_map = {}\n",
    "for rep, others in merge_map.items():\n",
    "    reverse_map[rep] = rep  # rep maps to itself\n",
    "    for gene in others:\n",
    "        reverse_map[gene] = rep\n",
    "\n",
    "# === Step 2: Load a specific tissue's gene list ===\n",
    "# Replace this with your actual tissue file path\n",
    "tissue_df = pd.read_csv(\"../../results/mouse/heart_essential_genes.csv\")\n",
    "lnc_ids = tissue_df['lncRNA_ID']\n",
    "\n",
    "# === Step 3: Replace lncRNA_IDs with their representative IDs ===\n",
    "representative_ids = lnc_ids.apply(lambda x: reverse_map.get(x, x))\n",
    "\n",
    "# === Step 4: Remove duplicates and save to file ===\n",
    "unique_reps = representative_ids.drop_duplicates().to_frame(name='lncRNA_ID')\n",
    "unique_reps.to_csv(\"deduplicated_mouse_heart_essential_genes.csv\", index=False, header=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esslnc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
